<!DOCTYPE html>
<html>
  <head>
    <title>Autobounds</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style>

      /* latin */
      @font-face {
      font-family: 'Roboto';
      font-style: normal;
      font-weight: 100;
      src: url(./resources/fonts/Roboto/Roboto-Thin.ttf) format('truetype');
      }
      /* latin */
      @font-face {
      font-family: 'Roboto';
      font-style: normal;
      font-weight: 300;
      src: url(./resources/fonts/Roboto/Roboto-Light.ttf) format('truetype');
      }
      /* latin */
      @font-face {
      font-family: 'Roboto';
      font-style: bold;
      font-weight: 700;
      src: url(./resources/fonts/Roboto/Roboto-Bold.ttf) format('truetype');
      }

      /* latin */
      @font-face {
      font-family: 'Raleway', 'Roboto';
      font-style: normal;
      font-weight: 400;
      src: url(./resources/fonts/Raleway/Raleway-Regular.ttf) format('truetype');
      }
      /* latin */
      @font-face {
      font-family: 'Raleway', 'Roboto';
      font-style: bold;
      font-weight: 700;
      src: url(./resources/fonts/Raleway/Raleway-SemiBold.ttf) format('truetype');
      }

      /* latin */
      @font-face {
      font-family: 'Great Vibes';
      font-style: normal;
      font-weight: 300;
      src: url(./resources/fonts/Great_Vibes/GreatVibes-Regular.ttf) format('truetype');
      }


      h1 {
      font-family: 'Raleway', 'Roboto';
      font-weight: 600;
      color: #A51C30;
      }

      h2 {
      font-family: 'Raleway', 'Roboto';
      font-weight: 400;
      color: #A51C30;
      }

      p {
      font-family: 'Roboto';
      font-weight: 300;
      sans-serif;
      }

      body {
      font-family: 'Roboto';
      font-weight: 300;
      sans-serif;
      }

      .footnote {
      position: absolute;
      bottom: 1.5%;
      left: 10%;
      text-align: left;
      width: 50;
      font-size: 65%;
      z-index: 1;
      }

      b, strong {
      font-family: 'Roboto';
      font-weight: 700;
      sans-serif;
      }

      table, th, tr, td {
      border-style:none;
      <!-- font-size: 100%; -->
      }

      tr.underline td{
      border-bottom: 1px solid black;
      }
      
      tr.start td{
      border-top: double black;
      }

      tr.end td{
      border-bottom: double;
      }

      td {
      padding-bottom: 1ex;
      vertical-align: top;
      }

      .footnote td {
      padding-bottom: 0ex;
      vertical-align: top;
      }

      .functiondef td {
      vertical-align: middle;
      padding-bottom: 0ex;
      line-height: 1
      }

      sup {
      vertical-align: top; 
      font-size: 0.5em;
      top: -.5ex;
      }

      ul, ol {
      padding-top: 0ex;
      }

      li {
      padding-bottom: 1ex;
      }

      .remark-slide-content {
      height: 100%;
      background-size: cover;
      }

      .inverse {
      background: #A51C30;
      color: #FFFFFF;
      }

      .remark-slide-content h1 {
      font-size: 275%;
      }

      .remark-slide-content h2 {
      font-size: 200%;
      }

      .remark-slide-content p {
      font-size: 30px;
      }

      .remark-slide-content li {
      font-size: 30px;
      padding-bottom: 1.5ex;
      }

      .remark-slide-content li li {
      font-size: 25px;
      padding-bottom: 0ex;
      }
      
      .remark-slide-content li:last-child{
      padding-bottom: 0ex;
      }

      .inverse h1, .inverse h2 {
      color: #f3f3f3;
      line-height: 0.8em;
      }

      .small {
      font-size: 80%;
      }

      .tiny {
      font-size: 60%;
      }
      
      .large {
      font-size: 120%;
      }

      .highlight {
      color: #A51C30;
      }

      .highlight_alt {
      color: #4E84C4;
      }

      a {
      color: #4E84C4;
      }

      .gray {
      color: lightgray;
      }

      table.center td {
      text-align: center;
      }
            
      .overlay {
      background-color: white;
      background-color: rgba(255,255,255,0.75);
      font-size: 150%;
      width: auto;
      position: absolute;
      padding: .25em;
      border-radius: .25em;
      }

      .summary {
      background-color: white;
      background-color: rgba(255, 255, 255, 0.6);
      font-size: 35px;
      display: table;
      text-align: center;
      vertical-align: middle;
      position: absolute;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      z-index: 2;
      }

      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }

      @keyframes slideup {
        0% {
        }
        100% {
          transform: translate3d(0px, -118.5px, 0px);
        }
      }
      img#slideup {
      animation: slideup 1s forwards;
      }

      @keyframes slideleft {
        0% {
        }
        100% {
          transform: translate3d(-100px, 0px, 0px);
        }
      }
      img#slideleft {
      animation: slideleft 1s forwards;
      }

      .stretch {
      transform: scale(1, 2.25)
      }

      
    </style>
  </head>
  <body>
    <textarea id="source">



<!-- <h1 style="font-size: 270%; text-align: left; margin-bottom: 20px">Quantifying Racial Bias in Policing with Imperfect Data</h1> -->
<!-- <img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 10%; top: 30%; width: 80%; opacity: .25; filter: blur(1px)"/> -->
<!-- <br><br><br><br><br><br><br><br><br> -->
<!-- <span class="today" style="margin-bottom: 20px"></span> -->
<!-- <br><br> -->
<!-- <\!-- Guilherme Duarte &nbsp; .tiny.highlight[**Penn**]<br> -\-> -->
<!-- <\!-- Noam Finkelstein &nbsp; .tiny.highlight[**JHU**]<br> -\-> -->
<!-- Dean Knox &nbsp; .tiny.highlight[**Penn**] <br> -->
<!-- <\!-- Will Lowe &nbsp; .tiny.highlight[**Hertie**] <br> -\-> -->
<!-- <\!-- Jonathan Mummolo &nbsp; .tiny.highlight[**Princeton**]<br> -\-> -->
<!-- <\!-- Ilya Shpitser &nbsp; .tiny.highlight[**JHU**] -\-> -->



<h1 style="font-size: 270%; text-align: left; margin-bottom: 20px">An Automated Approach<br>to Causal Inference<br>in Discrete Settings</h1>
<img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 15%; top: 30%; width: 70%; opacity: .25; filter: blur(1px)"/>
<br><br><br><br><br><br><br><br><br>
<!-- <span class="today" style="margin-bottom: 20px"></span> -->
Guilherme Duarte &nbsp; .tiny.highlight[**Penn**]<br>
Noam Finkelstein &nbsp; .tiny.highlight[**JHU**]<br>
Dean Knox &nbsp; .tiny.highlight[**Penn**] <br>
Jonathan Mummolo &nbsp; .tiny.highlight[**Princeton**]<br>
Ilya Shpitser &nbsp; .tiny.highlight[**JHU**]
<br><br><br>
R&R at *Journal of the American Statistical Association* (Theory & Methods)

???
- What we're going to show you today is a complete solution for partial identification in causal inference, given discrete data. By identification, I mean, ask a question, get some data, and obtain a single answer. 
This is what happens for example when you have a linear model that attends all the assumptions. Then the question "what  is the value of the beta coefficient?"  has a single answer. 
 Partial identification generalizes identification in the sense that 
Instead of getting a single answer, we get a range of possible answers. So instead of 
obtaining a value, for instance, 0.5, we obtain lower and upper bounds, 0.1, 0.7.

- We present a complete solution in the sense that it can handle any estimand, any causal structure in the form of DAG, and will always provide sharp bounds. Therefore, it gets the best possible answer for any classical threat to inference researchers often face such as measurement error, overlap, proxies, selection, and lots of others. Finally, our solution can also test some assumptions about models as we will see.

<!-- --- -->
<!-- <img src="./resources/images/intro_dag_01.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/intro_dag_02.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/intro_dag_03.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/intro_dag_04.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/intro_dag_05.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/> -->
---
<img src="./resources/images/klm_base.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/>

---

# Bounds can reconcile claims

- Scientists often need to reconcile competing claims
  - Scholars, plaintiffs, external monitors, police departments
  - Different data access, modeling approaches, etc.

???
- Competing claims are everywhere in policing
- Not just in science but also in litigation
  - One party alleges discrimination against minorities
  - Another says no, it's because of criminality
- Here's one way to square that
  - You tell me the causal structure
  - You tell me what information you have (both assumptions & data)
  - You tell me what the question is, the causal quantity
- I go look at all the possible worlds
  - All the DGPs that are consistent with the known facts
- And among these worlds, I give you the best and worst possible cases
  - Nonparametric means without functional form assumptions on the DGP
  - Sharp means that there's no way to narrow it down more. Generally hard to prove.
- But once we have those bounds, they're incredibly useful

--
- **A promising approach:** nonparametric sharp bounds

--
  - Claims outside the bounds can be immediately rejected

--
  - Claims inside the bounds must explain where additional info. comes from
    (e.g. hidden assumptions, parametric models)
--
- **The challenge:** hard to derive analytically <!-- .tiny[(Balke & Pearl '94)] -->
  - Most results are painstakingly hand-derived 
  - Prior algorithmic approaches only work in limited settings
  - Bounds available for only a handful of causal problems

---

# Nonparametric sharp bounds with no more tears

- We develop an automatic bounding algorithm
  - Handles confounding, missingness, selection, data fusion, mismeasurement,
    ecological inference, and much more
--
- How it works:

--
  - Draw DAG, enumerate assumptions, provide data
  
--
  - State your query (causal estimand)
  
--
  - We transform into polynomial programming problem

--
- Apply branch-and-bound, primal-dual optimization

--
  - Immediately produces valid non-sharp bounds

--
  - Iteratively refines bounds to guaranteed sharpness

--
  - Reports current degree of non-optimality while working

--
  - Produces conservative confidence intervals


<!-- --- -->

<!-- <\!-- <h1 style='font-size: 270%'>3. Feasible ing</h1> -\-> -->
<!-- # We propose ε-sharp bounds -->

<!-- - Efficient spatial branch-and-bound procedure -->
<!--   - Quickly produces valid non-sharp bounds -->
<!--   - Iteratively refines bounds toward sharpness -->

<!-- ??? -->
<!-- - We're going to be thinking about three kinds of issues: -->
<!-- - The first kind are **causal identification** issues:  -->
<!--   - With enough data, our procedure will always bracket the estimand (will be valid bounds) -->
<!--   - With enough time, it'll always give you an answer that is sharp (cannot be improved on further) -->
<!-- - The second kind are **computational** issues -->
<!--   - This procedure can be demanding, it may take a while to run -->
<!--   - But to our first point, if you stop early, at any point in this process -->
<!--   - The answer will still always be valid. That's very important -->
<!--   - They may be suboptimal, but they'll be valid. And we can guarantee the worst-case extent of that suboptimality -->
<!-- - Finally, we'll talk about statistical inference -->
<!--   - If you have a procedure that produces CI with nominal coverage for completely sharp bounds -->
<!--   - That procedure will give you conservative coverage for our ε-sharp bounds -->

<!-- -- -->
<!-- - Strong theoretical guarantees -->

<!-- -- -->
<!--   1. <u>Identification</u><sub>&nbsp;</sub> -->

<!-- -- -->
<!-- <br>**Infinite-*n*&ensp;validity:** will contain causal estimand<sup>&nbsp;</sup> -->

<!-- -- -->
<!-- <br>**Infinite-*t*&ensp;optimality:** will attain complete sharpness<sub>&nbsp;</sub> -->

<!-- -- -->
<!--   2. <u>Computation</u><sup>&nbsp;</sup><sub>&nbsp;</sub> -->

<!-- -- -->
<!-- <br>**Finite-*t*&ensp;validity:** will still contain causal estimand<sup>&nbsp;</sup> -->

<!-- -- -->
<!-- <br>**Finite-*t*&ensp;tightness:** worst-case looseness factor of ε<sub>&nbsp;</sub>  -->

<!-- -- -->
<!--   3. <u>Inference</u><sup>&nbsp;</sup><sub>&nbsp;</sub>  -->
<!-- -- -->
<!-- <br>**Finite-*n* conservativeness:** CI coverage for ε-sharp bounds<sup>&nbsp;</sup> <br> is conservative, compared to completely sharp bounds -->

---

class: center, middle, inverse

# Illustration #1:
# a simple bounding exercise

???
- so here's how we propose to do that

---

<img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/ms_base.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
---
<!-- <img src="./resources/images/ms_m.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/> -->
<!-- --- -->
<img src="./resources/images/ms_s.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/ms_s1.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/ms_s0.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
---

Observed data and all counterfactual manipulations<br>
are fully determined by joint distr. of response variables
<p style="position: absolute; top: 17%; font-size: 80%">
Greenland & Robins ('86),
Balke & Pearl ('94),
Frangakis & Rubin ('02)
</p>
<img src="./resources/images/ms_rvars.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>

---

Observed data and all counterfactual manipulations<br>
are fully determined by joint distr. of response variables
<p style="position: absolute; top: 17%; font-size: 80%">
Greenland & Robins ('86),
Balke & Pearl ('94),
Frangakis & Rubin ('02)
</p>
<img src="./resources/images/ms_rvars.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>

<table class="functiondef" style="position: absolute; left: 30%; top: 60%; width: 5%;">
  <tr>
    <td colspan="3" style="text-align: center; vertical-align: middle; border-bottom: 1px solid black"><span style="font-family: Great Vibes">R</span><sub>M</sub></td>
  </tr>
  <tr>
    <td>r<sub>M,1</sub></td>
    <td>=</td>
    <td>0</td>
  </tr>
  <tr>
    <td>r<sub>M,2</sub></td>
    <td>=</td>
    <td>1</td>
  </tr>
</table>

<table class="functiondef" style="position: absolute; left: 45%; top: 60%; width: 45%;">
<col style="width: 7.5%">
<col style="width: 2.5%">
<col style="width: 2.5%">
<col style="width: 20%">
<col style="width: 50%">
  <tr>
    <td colspan="4" style="text-align: center; vertical-align: middle; border-bottom: 1px solid black"><span style="font-family: Great Vibes">R</span><sub>S</sub></td>
    </td>
  </tr>
  <tr>
    <td>r<sub>S,1</sub>(m)</td>
    <td>=</td>
    <td style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>0</td>
          <td>if m=0</td>
        </tr>
        <tr>
          <td>0</td>
          <td>if m=1</td>
        </tr>
      </table>
    </td>
    <td> &emsp; (never stop) </td>
  </tr>
  <tr>
    <td>r<sub>S,2</sub>(m)</td>
    <td>=</td>
    <td style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>0</td>
          <td>if m=0</td>
        </tr>
        <tr>
          <td>1</td>
          <td>if m=1</td>
        </tr>
      </table>
    </td>
    <td> &emsp; (anti-minority stop) </td>
  </tr>
  <tr>
    <td>r<sub>S,3</sub>(m)</td>
    <td>=</td>
    <td style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>1</td>
          <td>if m=0</td>
        </tr>
        <tr>
          <td>0</td>
          <td>if m=1</td>
        </tr>
      </table>
    </td>
    <td> &emsp; (anti-white stop) </td>
  </tr>
  <tr>
    <td>r<sub>S,4</sub>(m)</td>
    <td>=</td>
    <td style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>1</td>
          <td>if m=0</td>
        </tr>
        <tr>
          <td>1</td>
          <td>if m=1</td>
        </tr>
      </table>
    </td>
    <td> &emsp; (always stop) </td>
  </tr>
</table>

---

Observed data and all counterfactual manipulations<br>
are fully determined by joint distr. of response variables
<p style="position: absolute; top: 17%; font-size: 80%">
Greenland & Robins ('86),
Balke & Pearl ('94),
Frangakis & Rubin ('02)
</p>
<img src="./resources/images/ms_rvars.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>

<br><br><br><br><br><br><br><br>
&emsp;&emsp; ATE&emsp;=&emsp;E[ Stop(minority) - Stop(white) ]<br><br>

--
&emsp;&emsp; ATE&emsp;=&emsp;Pr(always stop) + Pr(anti-minority stop)<br>

&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;- Pr(always stop) - Pr(anti-white stop)<br>

&emsp;&emsp; ATE&emsp;=&emsp;Pr(anti-minority stop) - Pr(anti-white stop)


---

<p style="position: absolute; left: 9%; top: 3%; width: 40%; z-index: 2;">
  <b>Assumption:</b>
</p>
<p style="position: absolute; left: 50%; top: 5.5%; width: 40%; z-index: 2; font-size: 100%">
  p( anti-white stop ) = 0
</p>
--
<p style="position: absolute; left: 9%; top: 8%; width: 40%; z-index: 2;">
  <b>Laws of probability:</b>
</p>
<p style="position: absolute; left: 50%; top: 10.25%; width: 40%; z-index: 2; font-size: 100%">
  &sum;<sub>k</sub> p( r<sub>S,k</sub> ) = 1,&ensp; &sum;<sub>k</sub> p( r<sub>M,k</sub> ) = 1
</p>
--
</p>

<img src="./resources/images/3d_base.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>
---

<p style="position: absolute; left: 9%; top: 3%; width: 40%; z-index: 2;">
  <b>Assumption:</b>
</p>
<p style="position: absolute; left: 50%; top: 5.5%; width: 40%; z-index: 2; font-size: 100%">
  p( anti-white stop ) = 0
</p>
<p style="position: absolute; left: 9%; top: 8%; width: 40%; z-index: 2;">
  <b>Laws of probability:</b>
</p>
<p style="position: absolute; left: 50%; top: 10.25%; width: 40%; z-index: 2; font-size: 100%">
  &sum;<sub>k</sub> p( r<sub>S,k</sub> ) = 1,&ensp; &sum;<sub>k</sub> p( r<sub>M,k</sub> ) = 1
</p>
<img src="./resources/images/3d_lawprob.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>
---

**Observed stop margin:**<br>
p( stop )
<p style="position: absolute; left: 50%; top: 5.5%;  z-index: 2; font-size: 100%;">
  p( min. ) p( anti-min. stop )
  <br> &emsp;+ p( min. ) p( always stop )
  <br> &emsp;&ensp;&emsp; + [ 1 - p( min. ) ] p( always stop )
</p>
<img src="./resources/images/3d_stopmargin.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>
---

**Observed stop records:**<br>
p( minority | Stop=1 )

<p style="position: absolute; left: 47.5%; top: 5.5%;  z-index: 2; font-size: 100%;">
  p( min. ) p( anti-min. stop OR always stop )
  <br> &emsp; / [ p( min. ) p( anti-min. stop) + p( always stop ) ]
</p>
<img src="./resources/images/3d_stoprecords.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>

---

**Remaining feasible region**<br>
<img src="./resources/images/3d_feasible.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>

---

**Population benchmarking:**<br>
<!-- External reference for p( minority ) -->
<p style="position: absolute; left: 60%; top: 5.5%;  z-index: 2; font-size: 100%;">
  &alpha;&ensp;&le;&ensp;p( min. )&ensp;&le;&ensp;&beta;<br>
</p>
<img src="./resources/images/3d_benchmark.png" style="position: absolute; left: -5%; top: 20%; height: 80%; z-index: ;"/>

???
- We could also bring in additional side information
- For example, we might know that a neighborhood's residents are 60% minority
- Of course that doesn't mean that exactly 60% of police encounters are with minorities
- That depends on where and when officers go on patrol
- But we could could say, officers probably aren't encountering more than 80% minorities, or less than 40%

---

# Drawing chained inferences

- Individual real-world datasets may have limited value
  - Contaminated by selection, measurement error,<br>

--
    unobserved confounding, missingness, noncompliance
--
- But informativeness of multiple datasets can be more<br>
  than the intersection of implied bounds in isolation

--
- **Three logicians walk into a bar**

--
  - Bartender: "Do you all want a beer?"

--
  - Logician 1: "I don't know."

--
  - Logician 2: "I don't know."

--
  - Logician 3: "Yes."

--
- But automating **provably sharp** chained inferences from multiple incomplete
  sources is challenging
  
---

class: center, middle, inverse

# Illustration #2:
# a slightly harder problem

---
<img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;">
---
<img id="slideup" src="./resources/images/mbs_base.png" style="position: absolute; left: 2.5%; top: 12.5%; width: 100%; z-index: ;"/>
<!-- --- -->
<!-- <img src="./resources/images/mbs_base.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/> -->
---
<img src="./resources/images/mbs_s1.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/mbs_s0.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/mbs_m.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/mbs_b.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/mbs_rvars.png" style="position: absolute; left: 2.5%; top: -5%; width: 100%; z-index: ;"/>

--
<table class="functiondef" style="position: absolute; left: 25%; top: 55%; width: 5%;">
  <tr>
    <td colspan="3" style="text-align: center; vertical-align: middle; border-bottom: 1px solid black"><span style="font-family: Great Vibes">R</span><sub>M</sub></td>
  </tr>
  <tr>
    <td>r<sub>M,1</sub></td>
    <td>=</td>
    <td>0</td>
  </tr>
  <tr>
    <td>r<sub>M,2</sub></td>
    <td>=</td>
    <td>1</td>
  </tr>
</table>

<table class="functiondef" style="position: absolute; left: 38%; top: 55%; width: 5%;">
  <tr>
    <td colspan="3" style="text-align: center; vertical-align: middle; border-bottom: 1px solid black"><span style="font-family: Great Vibes">R</span><sub>B</sub></td>
  </tr>
  <tr>
    <td>r<sub>B,1</sub></td>
    <td>=</td>
    <td>0</td>
  </tr>
  <tr>
    <td>r<sub>B,2</sub></td>
    <td>=</td>
    <td>1</td>
  </tr>
</table>

<table class="functiondef" style="position: absolute; left: 50%; top: 55%; width: 26%;">
<col style="width: 10%">
<col style="width: 2.5%">
<col style="width: 2.5%">
<col style="width: 85%">
  <tr>
    <td colspan="4" style="text-align: center; vertical-align: middle; border-bottom: 1px solid black"><span style="font-family: Great Vibes">R</span><sub>S</sub></td>
  </tr>
  <tr>
    <td>r<sub>S,1</sub>(m)</td>
    <td>=</td>
    <td class="stretch" style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>0</td>
          <td>if m=0, b=0</td>
        </tr>
        <tr>
          <td>0</td>
          <td>if m=0, b=1</td>
        </tr>
        <tr>
          <td>0</td>
          <td>if m=1, b=0</td>
        </tr>
        <tr>
          <td>0</td>
          <td>if m=1, b=1</td>
        </tr>
      </table>
    </td>
  </tr>
  <tr>
    <td>&emsp;&vellip;</td>
  </tr>
<tr>
    <td>r<sub>S,16</sub>(m)</td>
    <td>=</td>
    <td class="stretch" style="font-weight: 100; font-size: 200%; padding-bottom: .3ex;">{</td>
    <td>
      <table>
        <tr>
          <td>1</td>
          <td>if m=0, b=0</td>
        </tr>
        <tr>
          <td>1</td>
          <td>if m=0, b=1</td>
        </tr>
        <tr>
          <td>1</td>
          <td>if m=1, b=0</td>
        </tr>
        <tr>
          <td>1</td>
          <td>if m=1, b=1</td>
        </tr>
      </table>
    </td>
  </tr>
</table>

<!-- --- -->

<!-- class: center -->

<!-- # Applicable to essentially <br>any research obstacle -->

<!-- <img src="./resources/images/cases_xy.png" style="position: absolute; left: 2.5%; top: 40%; width: 95%; z-index: ;"/> -->

<!-- ??? -->
<!-- Now I’m going to introduce the idea of partial identification a little more concretely, -->
<!-- We use a super boring example, simple confounding. -->
<!-- - In this case, we have observational data on two variables, X and Y, -->
<!-- and both are confounded by a common cause, U. -->
<!-- - U is unobserved: this red box shows everything that we have in the data -->
<!-- - just for simplicity, let’s say that everything is binary -->
<!-- - We would like to calculate the Average Treatment Effect of X on Y, -->
<!-- but this is obviously impossible, given the unobserved confounding. -->

<!-- - so what do we do? option 1 is to just give up -->
<!-- - option 2 is to assume that the confounding does not exist, -->
<!-- but this would be clearly false. -->
<!-- - we’re to show you the third way: bounding -->
<!-- - for example, we could say that the ATE is somewhere in [-1,1]. This is definitely true, but it’s not very informative. These are loose bounds. -->
<!-- - The only way that an ATE of 1 could happen is if all the control units have an outcome of Y=0 -->
<!-- - If we get data that shows this isn’t true, we could use that information to narrow the  range of possible values for the ATE, for example for somewhere in [-0.1, 0.5]. -->
<!-- - We look for, then, the narrowest possible values for bounds. -->
<!-- - And moreover, this solution must be robust to the point that if the lower bound is equal to the upper bound, we have point identification. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding<br>&nbsp;</b></td> -->
<!--     <td><\!-- <b>Mediator-based selection</b> -\-></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><\!-- <img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/> -\-></td> -->
<!--   </tr> -->
<!--   <\!-- <tr style="height: 50px;"></tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><b>Measurement error</b></td> -\-> -->
<!--   <\!--   <td><b>Outcome-based selection</b></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <\!-- <td><b>Nonresponse</b></td> -\-> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <\!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->

<!-- ??? -->
<!-- That confounding case is a relatively easy one. We can derive sharp bounds through the ideas I just mentioned, using simple operations on the number of treated units, average Y in the treated units, and average Y in the control units. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <\!-- <tr style="height: 25px;"></tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><b>Measurement error</b></td> -\-> -->
<!--   <\!--   <td><b>Outcome-based selection</b></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <\!-- <td><b>Nonresponse</b></td> -\-> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <\!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->

<!-- ??? -->
<!-- However, a different but also very simple causal structure, such as the mediator-based selection, -->
<!-- took Knox, Lowe, Mummolo, several pages to derive a solution in an APSR paper. -->
<!-- Here are those pages. -->
<!-- --- -->



<!-- <img src="./resources/images/klm_proofs_00.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_01.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_02.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_03.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_04.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_05.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_06.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_07.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_08.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_09.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_10.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_11.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_12.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_13.png" style="width: 19%; z-index: 1;"/> -->
<!-- <img src="./resources/images/klm_proofs_14.png" style="width: 19%; z-index: 1;"/> -->

<!-- -- -->
<!-- <div class="summary"> -->
<!-- <br><br><br> -->
<!-- <h1 style="font-size: 200%; color: black">But requires<br>extensive derivation<br>even in small graphs</h1> -->
<!-- </div> -->
<!-- ??? -->
<!-- Even showing a small structure, this problem requires extensive derivation. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <\!-- <tr style="height: 25px;"></tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><b>Measurement error</b></td> -\-> -->
<!--   <\!--   <td><b>Outcome-based selection</b></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <\!-- <tr> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!--   <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   <\!-- </tr> -\-> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <\!-- <td><b>Nonresponse</b></td> -\-> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <\!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->

<!-- ??? -->
<!-- Other problems with simple structures also require convoluted solutions, which have been developed and published in the best journals. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><\!-- <b>Measurement error</b> -\-></td> -->
<!--     <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><\!-- <img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/> -\-></td>  -->
<!--     <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <\!-- <td><b>Nonresponse</b></td> -\-> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <\!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->
<!-- ??? -->
<!-- Sharp bounds for the outcome-based selection, for instance, was a recent JASA paper. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
<!--     <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <\!-- <td><b>Nonresponse</b></td> -\-> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <\!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->

<!-- ??? -->
<!-- A measurement error solution was the object of study of one of our co-authors. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
<!--     <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
<!--     <\!-- <td><b>Noncompliance</b></td> -\-> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <\!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -\-> -->
<!--   </tr> -->
<!-- </table> -->

<!-- ??? -->
<!-- Finally, we also have the classic Manski bounds and IV bounds. -->
<!-- --- -->

<!-- <table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;"> -->
<!--   <colgroup> -->
<!--     <col style="width: 50%;"/> -->
<!--     <col style="width: 50%;"/> -->
<!--   </colgroup> -->
<!--   <tr> -->
<!--     <td><b>Confounding</b></td> -->
<!--     <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
<!--     <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!--   <tr style="height: 25px;"></tr> -->
<!--   <tr> -->
<!--     <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
<!--     <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
<!--     <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
<!--   </tr> -->
<!-- </table> -->


<!-- ??? -->
<!-- All those causal structures are very simple. -->
<!-- - Although all those solutions are important and helpful by themselves,  -->
<!-- they have a limitation. Small deviations to the structure of those graph will -->
<!-- turn the solutions invalid. If they are in face of a new structure, researchers have  -->
<!-- to derive new bounds, even for very simple graphs. -->

<!-- - The main purpose of this research is to answer the question: -->
<!-- What if we are able to automatize solutions? What if we can do that -->
<!-- such that  researchers  -->
<!-- could continue on focusing on their problem and stop populating  -->
<!-- methods conferences? -->

---

# State of the art

- **Point** identification has already been automated
  - *do*-calculus .tiny[(Pearl '95; Huang & Valtorta '06; Shpitser & Pearl '06)]
  - Observational + experimental data .tiny[(Lee et al., 2020; Lee and Shpitser, 2020)]
  <!-- - Some work on special case when all variables are linear case .tiny[(Kumor et al '21)] -->

???
By automation of causal inference, I mean, to come up with an algorithm to which 
you introduce data, assumptions, a query, and it spits out a way of rewriting this query 
with the data.
- This is the traditional way of doing causal inference in some fields.
For nonparametric settings, there are algorithms such as ID and IDC, you have do-calculus, and all of them
are proved to be complete.  Completeness means that
if a solution exists, the algorithm is guaranteed to find it. This approach was extended
into aID and gID algorithms, which mix observational and experimental data.

--
- But **partial** identification (bounding) is much harder
  - Linear programming works for some cases .tiny[(Balke & Pearl '97)]
  - But many problems can't be represented as linear programs

???
For partial Identification, this is much harder. 
In the literature, there are only specific solutions, for example, the solution for instrumental variable bounds using linear programming. Not every problem can be represented like that, though.
  
--
- General solution to partial ID has been elusive
  - Symbolic solution is theoretically possible .tiny[(Geiger & Meek '99)]
    <br>but in practice is wildly computationally infeasible
  - Problem instances are often nonconvex,

--
numeric approaches that fail to discover global extrema produce *invalid bounds*
  
???
A general and complete algorithm was thought to be possible before, but 
in practice, this is wildly computationally infeasible.

---

# Our solution: "Autobounds"

- Transform causal problems &rightarrow; optimization problems
    - Solves any partial identification problem
    - And also every point identification problem
???
Now this solution exists. I introduce you to autobound.
Autobound does exactly what I have told you. You introduce
assumptions, for instance a DAG, and data, you ask a causal query
and the algorithm will return you the narrowest bounds for this quantity.

Autobound is complete in the sense that it solves
any partial identification problem as well as point identification questions.
--
- Efficient spatial branch-and-bound procedure
  - Quickly produces valid non-sharp bounds
  - Iteratively refines bounds toward sharpness
???
There are only two requirements, discrete data, and enough time. If you have
discrete data, you will have valid bounds. And if you leave the algorithm running
enough time, you will have valid sharp bounds. And if the procedure is too
computational demanding, you can stop it whenever you want introducing 
a parameter epsilon as a stopping threshold and those bounds will be
epsilon-sharp.
--

- Strong theoretical guarantees
  - Guaranteed anytime validity of bounds
  - Guaranteed worst-case looseness of non-sharp bounds
  - Guaranteed eventual sharpness of bounds
  - Guaranteed conservative coverage of CI
???
Finally, it is possible to construct confidence intervals with nominal coverage for
completely sharp bounds, as we will show.
---


class: center, middle, inverse

# Discrete causal inference
# is polynomial programming

---

# Constraints are polynomials
<img src="./resources/images/obsqty_joint_1.png" style="position: absolute; left: 20%; top: 35%; width: 65%; z-index: ;"/>
???
- say we have the joint distribution on the observed variables 
- we know we can reexpress that through the causal markov factorization
---
# Constraints are polynomials
<img src="./resources/images/obsqty_joint_2.png" style="position: absolute; left: 20%; top: 35%; width: 65%; z-index: ;"/>
???
- and we can expand that in terms of the response variables
- looking at all strata for this variable
- which would give us the result that we're interested in (INDICATOR)
- and how likely are those strata, which I'm denoting with q here (PROBS)
- so if we look at minority encounters, then the probability of seeing a stop is the probability of always stops plus the probability of anti-minority stops
- and we can keep doing that all the way down the tree
---
# Constraints are polynomials
<img src="./resources/images/obsqty_margin.png" style="position: absolute; left: 20%; top: 35%; width: 65%; z-index: ;"/>
???
- And if we only observe some marginal distribution
- Well, we can rewrite that by collapsing out, or summing over, the unobserved variables
---
# Constraints are polynomials
<img src="./resources/images/obsqty_cond_1.png" style="position: absolute; left: 5%; top: 30%; width: 95%; z-index: ;"/>
???
- And if we're talking about observed conditional distributions, we can do the same r-variable expansion
- Then moving the denominator over to the other side
- We have an observed scalar times a polynomial equals a polynomial
- Which is a polynomial equation

---
# Constraints are polynomials
<img src="./resources/images/obsqty_cond_2.png" style="position: absolute; left: 5%; top: 30%; width: 95%; z-index: ;"/>
???
- And if we're talking about observed conditional distributions, we can do the same r-variable expansion
- Then moving the denominator over to the other side
- We have an observed scalar times a polynomial equals a polynomial
- Which is a polynomial equation
---
# Constraints are polynomials
<img src="./resources/images/obsqty_cond_3.png" style="position: absolute; left: 5%; top: 30%; width: 95%; z-index: ;"/>
???
- And if we're talking about observed conditional distributions, we can do the same r-variable expansion
- Then moving the denominator over to the other side
- We have an observed scalar times a polynomial equals a polynomial
- Which is a polynomial equation

---

# Discrete causal inference<br>is polynomial programming

- Polynomial constraints:
  - Observed joint, marginal, conditional probabilities

???
- So what I showed you is any information about observed joint, marginal, or conditional distributions is a polynomial constraint
- And as I'll show you later, assumptions about the response function (monotonicity, or how one treatment disables another's effects) are linear (and therefore polynomial) constraints
- Finally, we know that if you have an additive causal estimand that manipulates all inputs, that's an objective function that just adds and subtracts r-variable probabilities
- If your estimand lets one variable take its natural value and manipulates another, that's going to be a higher-order polynomial objective function
- If you have a multiplicative causal effect, that might look like a polynomial fractional expression at first (one polynomial divided by another)
- But we can show that there's a slack variable reformulation that linearizes or polynomializes
- And of course, causal quantities that are strictly monotonic transformations of those are fine too

--
  - Monotonicity, disabling, elimination assumptions

--
- Polynomial objective functions:
  - Additive effects (joint, total, mediated)

--
  - Multiplicative effects

--
  - Strictly monotonic transformations

---
<img src="./resources/images/constraints_lawprob0.png" style="position: absolute; left: 35%; top: 10.8%; scale: 50%; height: 74.2%; z-index: ;"/>
???
- so let's return to our example now
- our DGP has to satisfy the laws of probability, which means these strata proportions must be nonnegative
---
<img src="./resources/images/constraints_lawprob1mb.png" style="position: absolute; left: 35%; top: 10%; scale: 50%; height: 75%; z-index: ;"/>
???
- the joint distribution over race and behavior (these red variables) has to sum to 1
---
<img src="./resources/images/constraints_lawprob1s.png" style="position: absolute; left: 35%; top: 10%; scale: 50%; height: 75%; z-index: ;"/>
???
- if we look at all the possible police responses, or blue potential stop functions, they have to sum to one too
---
<img src="./resources/images/constraints_m_benchmark.png" style="position: absolute; left: 26%; top: 10%; scale: 50%; height: 75%; z-index: ;"/>
???
- the marginal distribution of race (adding up the m=1 terms) has to obey our population benchmark constraint
---
<img src="./resources/images/constraints_b.png" style="position: absolute; left: 35%; top: 10%; scale: 50%; height: 75%; z-index: ;"/>
???
- and the marginal distribution of behavior (adding the b=1 terms) has to match what our speed sensors saw
- so all of these so far are linear constraints
- Balke & Pearl examined these decades ago
---
<img src="./resources/images/constraints_s.png" style="position: absolute; left: 2.5%; top: 25%; scale: 50%; height: 50%; z-index: ;"/>
???
- but once we start talking about variables that are causally downstream of other variables
- now the degree of our polynomials starts to increase
- now I have to ask, what's the probability that I see a white person speeding (m0 b1)
- then look at kinds of officers would stop them (all the response functions that would produce a stop)
- and how likely those are, multiply them, add them up
- plus the probability that I see a minority speeding, and what scenarios they get stopped in, and so on
- by inspection, you can see this is an indefinite matrix
- so here we have a nonconvex quadratic constraint
- and similarly, our objective function is a nonconvex quadratic expression (I won't show it here)
<!-- --- -->
<!-- <img src="./resources/images/objective.png" style="position: absolute; left: 2.5%; top: 25%; scale: 50%; height: 50%; z-index: ;"/> -->
---

# We have a problem

???
- Generalization of Balke & Pearl's LP bounds, which run very fast
- It's known that nonconvex QCQPs are NP-hard
- I'll show you our approach in a second, and for this small case it doesn't take that long
- But in general they can get nasty fast
- And quadratic problems are really just the beginning
- As the DAGs get larger, the degree of the polynomials grows

--
<img src="./resources/images/program.png" style="position: absolute; left: 15%; top: 23%; scale: 50%; height: 50%; z-index: ;"/>
--
<br><br><br><br><br><br><br><br><br>
- Generalization of LP bounds (run very fast) .tiny[(Balke & Pearl '94)]

--
- Nonconvex QCQPs are known to be NP-hard

--
- Larger DAGs &rarr; higher degree, greater difficulty

---

class: center, middle, inverse

# An efficient procedure for
# computing ε-sharp bounds

???
- given how difficult this optimization problem can often be, 
we're now going to develop an approximate solution
- but we're going to carefully design that approximation so that beyond just being fast, 
it's also going to have a number of desirable theoretical properties

---

# The procedure

- Spatial branch & bound .tiny[(Land & Doig '60)]
  - Recursively divide model space into branches
  - Eliminate branches that cannot possibly be optimal
  - Much faster than brute-force enumeration
???
This solution is a spatial branch & bound method, which 
recursively divide model space into branches, and eliminate the ones 
that cannot be optimal. This is much faster than brute-force.
<!-- --- -->
<!-- <img src="./resources/images/2d_feasible.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
---
<img src="./resources/images/3d_feasible.png" style="position: absolute; left: -5%; top: 10%; height: 80%; z-index: ;"/>
???
- to illustrate, I'm going to return to that simple 3-parameter problem. Remember this feasible region.
---
<img src="./resources/images/2d_function.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- here, I'm laying the feasible region down sideways, so the original z-axis is now our x-axis
and on the y-axis, we have the objective function: the causal effect
- every point on this line is feasible, in other words, is consistent with the observed information.
- our goal is find the best and worst possible treatment effects in this feasible region
- obviously that's easy to do in this simple case: start in the middle & go uphill until you find the max, then go downhill until you find the min
- but we want a procedure that will generalize to much harder cases, so let's start by finding a lower bound
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_4.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_5.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_6.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_7.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_lowerbound_8.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
---
<img src="./resources/images/2d_lowerbound_function.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- the blue dashed line is the primal problem.
- our strategy is to divide up the model space into 8 branches, these 8 red lines.
and on those gray areas, we know we don't have to search there
- in each branch, we're going to compute a relaxation that we can guarantee will sit below the true objective function
- specifically, this will be a linear programming relaxation that are fast to solve

---
<img src="./resources/images/2d_lowerbound_8.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
???
- it's super hard to work directly with the primal  problem, so we're mostly going to work with this piecewise dual function (the red)
- now, we don't know how loose this dual is
- it could be very tight on the left and very loose on the right.
- but as far as we know, the right part is the most promising region to search
---
<img src="./resources/images/2d_lowerbound_branchbound_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- so we go grubbing around in this branch and we find us a feasible DGP
- this is one model that's consistent with the constraints
- not necessarily the worst one, it's just any old model
- but that lets us do a lot of things
---
<img src="./resources/images/2d_lowerbound_branchbound_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- first, it lets us say, whatever the true lower bound is, it has to be here or lower
- in other words, we have an upper bound on the lower bound
- which means, second, whereever the true lower bound lives, it can't be...
---
<img src="./resources/images/2d_lowerbound_branchbound_3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- here on the left
- because all these branches over here on can't possibly produce something worse than what we've already discovered
- so we can rule out huge parts of the model space, that don't need to be explored any more
---
<img src="./resources/images/2d_lowerbound_branchbound_4.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- and finally, because we can guarantee that this red dual sits below the blue primal everywhere in the space
- (even though it's hard to look at the primal directly)
- minimizing the dual will give us a lower bound on the lower bound
- so, those things are actually pretty close, so lets set the minimization problem aside now and turn to maximization
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_4.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_5.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_6.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_7.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
<!-- --- -->
<!-- <img src="./resources/images/2d_upperbound_8.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->
---
<img src="./resources/images/2d_upperbound_function.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- now we'll repeat that same process, but do our relaxations in the opposite direction, so the dual sits *above* the primal. And we do the same procedure until we find the upper bound.
---
<img src="./resources/images/2d_upperbound_8.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/> -->

---
<img src="./resources/images/2d_upperbound_branchbound_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>

---
<img src="./resources/images/2d_upperbound_branchbound_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
---
<img src="./resources/images/2d_upperbound_branchbound_3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>

---
<img src="./resources/images/2d_upperbound_branchbound_4.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>

---
<img src="./resources/images/2d_upperbound_branchbound_5.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
- find an even better feasible point
---
<img src="./resources/images/2d_upperbound_branchbound_6.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
---
<img src="./resources/images/2d_upperbound_epsilonsharp_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- so, to recap
---
<img src="./resources/images/2d_upperbound_epsilonsharp_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- we have some feasible points on the primal
- these are DGPs that are extreme, but are totally consistent with the information we have
- again, there could be other admissible DGPs that are even more extreme
- that we just haven't found yet
---
<img src="./resources/images/2d_upperbound_epsilonsharp_3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- then, we have extreme points on the dual, which definitely contain every DGP that could have produced the data, so, these are valid bounds on the treatment effect, but they could be too wide, we don't know
---
<img src="./resources/images/2d_upperbound_epsilonsharp_5.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
???
- so we have an inner bound... and an outer bound
- what we're going to report to readers is the outer bound, which again, is a guaranteed valid causal bound
- but the existence of the inner bound lets us offer some guarantees about the looseness of what we report
- if you think about the best case, it could be that what we have in red are actually already the true sharp bounds
  - in other words, it could be that as we keep exploring
  - we'll find more and more extreme feasible DGPs
  - which would push this blue range outwards
- and the worst case is that our reported red bounds are too loose
  - and as we keep refining our dual function
  - the red bounds will move inwards until they meet the blue
- in that case,we have a measure of this 
  -  worst-case looseness factor and that's what we call epsilon
- If a researcher wants to stop in a certain epsilon, we will say he has epsilon-valid bounds.
---

# The procedure

- Spatial branch & bound .tiny[(Land & Doig '60)]
  - Recursively divide model space into branches
  - Eliminate branches that cannot possibly be optimal
  - Much faster than brute-force enumeration

???
- It is important to say here that 
Polynomial programming solvers are not something that we've developed ourselves, 
but this is a research area where there are industry grade solvers. New 
efficient methods can be developed in the future.
--
- Many algo. components .tiny[(Gamrath et al. '20; Vigerske & Gleixner '17)]
  - Presolving (eliminate redundant variables, constraints)
  - Efficient branching strategies, primal exploration heuristics
  - Linear-programming relaxations for local dual problem
???
- There are also many stages of this process that I've abstracted away
From presolving, like eliminating variables To efficient branching and primal exploration strategies
- But even so, setting up these problems is still something of an art.

---

class: center, middle, inverse

# Relaxing assumptions
# in policing research

---
<img src="./resources/images/intro_dag_06.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/>
---
<img id="slideleft" src="./resources/images/klm_base.png" style="position: absolute; left: 2.5%; top: 20%; width: 100%; z-index: ;"/>
---

# Assumptions in KLM (2020)

--
- **Assumption 1 (Mandatory Reporting):** <br>
  &emsp;Force(race, no stop) = 0 for race .small[&in;] {white, min.}
--

- **Assumption 2 (Stop Monotonicity):** <br>
  &emsp;Stop(minority) &ge;   Stop(white)
--

- **Assumption 3 (Nonseverity of Racial Stops):** <br>
  &emsp;On average, Force(race, decision) is higher<br>
  &emsp;in always-stops than anti-minority stops, for<br>
  &emsp;race .small[&in;] {white, min.} and decision .small[&in;] {stop, no stop}
--

- **Assumption 4 (Ignorability of Race):** <br>
  &emsp; Race &perp; Stop(race)<br>
  &emsp; Race &perp; Force(race, decision)

---

<img src="./resources/images/klm_relax_0.png" style="position: absolute; left: 0%; top: 00%; width: 100%; z-index: ;"/>

---

<video class="media" style="position: absolute; width: 100%; left: 0%; top: 0%" preload="auto" onclick="this.play();">
  <source src="./resources/videos/baseline_video.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

---

<img src="./resources/images/klm_relax_1.png" style="position: absolute; left: 0%; top: 0%; width: 100%; z-index: ;"/>
---

# Assumptions in KLM (2020)

- **Assumption 1 (Mandatory Reporting):** <br>
  &emsp;Force(race, no stop) = 0 for race .small[&in;] {white, min.}
- **Assumption 2 (Stop Monotonicity):** <br>
  &emsp;Stop(minority) &ge;   Stop(white)
- .highlight[**Assumption 3 (Nonseverity of Racial Stops):** <br>
  &emsp;On average, Force(race, decision) is higher<br>
  &emsp;in always-stops than anti-minority stops, for<br>
  &emsp;race .small[&in;] {white, min.} and decision .small[&in;] {stop, no stop}]
- **Assumption 4 (Ignorability of Race):** <br>
  &emsp; Race &perp; Stop(race)<br>
  &emsp; Race &perp; Force(race, decision)


---
<img src="./resources/images/klm_relax_2.png" style="position: absolute; left: 0%; top: 0%; width: 100%; z-index: ;"/>
---

# Assumptions in KLM (2020)

- **Assumption 1 (Mandatory Reporting):** <br>
  &emsp;Force(race, no stop) = 0 for race .small[&in;] {white, min.}
- .highlight[**Assumption 2 (Stop Monotonicity):** <br>
  &emsp;Stop(minority) &ge;   Stop(white)]
- **Assumption 3 (Nonseverity of Racial Stops):** <br>
  &emsp;On average, Force(race, decision) is higher<br>
  &emsp;in always-stops than anti-minority stops, for<br>
  &emsp;race .small[&in;] {white, min.} and decision .small[&in;] {stop, no stop}
- **Assumption 4 (Ignorability of Race):** <br>
  &emsp; Race &perp; Stop(race)<br>
  &emsp; Race &perp; Force(race, decision)


---
<img src="./resources/images/klm_relax_3.png" style="position: absolute; left: 0%; top: 0%; width: 100%; z-index: ;"/>
---
<img src="./resources/images/klm_relax_4.png" style="position: absolute; left: 0%; top: 0%; width: 100%; z-index: ;"/>

---

class: center, middle, inverse

# Addresses all common
# research obstacles

???
Now that we showed how we solve the optimization problems, 
we will demonstrate how autobound works in practice.

---

name: zoo

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td></td>
    <!-- <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td> -->
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <!-- <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td> -->
  </tr>
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Confounding</b></td> -->
  <!--   <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
  <!--   <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Confounding</b></td> -->
  <!--   <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
  <!--   <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Confounding</b><br>&nbsp;</td>
    <!-- <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td> -->
  </tr>
  <tr>
    <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td>
    <!-- <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td> -->
  </tr>
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
  <!--   <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Confounding</b><br></td>
    <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <!-- <tr style="height: 25px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Nonresponse<br>(Manski, 1990)</b></td> -->
  <!--   <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td> -->
  <!--   <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
  <!-- </tr> -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Confounding</b><br></td>
    <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Nonresponse<br>(Manski, 1990)</b></td>
    <!-- <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td> -->
  </tr>
  <tr>
    <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td>
    <!-- <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td> -->
  </tr>
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 2.5%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr>
    <td><b>Mediator-based selection<br>(Knox, Lowe, Mummolo, 2020)</b></td>
    <td><b>Outcome-based selection<br>(Gabriel et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_klm.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Confounding</b></td>
    <td><b>Measurement error<br>(Finkelstein et al, 2020)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_xy.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_measurement.png" style="width: 100%; z-index: ;"/></td>
  </tr>
  <tr style="height: 25px;"></tr>
  <tr>
    <td><b>Nonresponse<br>(Manski, 1990)</b></td>
    <td><b>Noncompliance<br>(Balke and Pearl, 1997)</b></td>
  </tr>
  <tr>
    <td><img src="./resources/images/cases_nonresponse.png" style="width: 100%; z-index: ;"/></td>
    <td><img src="./resources/images/cases_iv.png" style="width: 100%; z-index: ;"/></td>
  </tr>
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 1%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr> 
    <td><b>Noncompliance </b><span class="tiny">(Balke & Pearl '94)</td>
    <td><!-- <b>Outcome-based selection </b><span class="tiny">(Gabriel et al. '21) --></td>  
  </tr> 
  <tr> 
    <td><img src="./resources/images/cases_iv.png" style="width: 45%; z-index: ;"/></td> 
    <!-- <td><img src="./resources/images/cases_outcomeselection.png" style="width: 45%; z-index: ;"/></td>  -- -->
  </tr>
  <tr> 
    <td><img src="./resources/images/model_a_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <!-- <td><img src="./resources/images/model_b_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  </tr> 
  <!-- <tr style="height: 15px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Measurement error </b><span class="tiny">(Finkelstein et al. '20)</td>  -->
  <!--   <td><b>Nonresponse </b><span class="tiny">(Manski '90)</td>  -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_measurement.png" style="width: 45%; z-index: ;"/></td>  -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 45%; z-index: ;"/></td>  -->
  <!-- </tr> -->
  <!-- <tr>  -->
  <!--   <td><img src="./resources/images/model_c_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  <!--   <td><img src="./resources/images/model_d_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  <!-- </tr>  -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 1%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr> 
    <td><b>Noncompliance </b><span class="tiny">(Balke & Pearl '94)</td>
    <td><b>Outcome-based selection </b><span class="tiny">(Gabriel et al. '21)</td> 
  </tr> 
  <tr> 
    <td><img src="./resources/images/cases_iv.png" style="width: 45%; z-index: ;"/></td> 
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 45%; z-index: ;"/></td> 
  </tr>
  <tr> 
    <td><img src="./resources/images/model_a_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <td><img src="./resources/images/model_b_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
  </tr> 
  <!-- <tr style="height: 15px;"></tr> -->
  <!-- <tr> -->
  <!--   <td><b>Measurement error </b><span class="tiny">(Finkelstein et al. '20)</td>  -->
  <!--   <td><b>Nonresponse </b><span class="tiny">(Manski '90)</td>  -->
  <!-- </tr> -->
  <!-- <tr> -->
  <!--   <td><img src="./resources/images/cases_measurement.png" style="width: 45%; z-index: ;"/></td>  -->
  <!--   <td><img src="./resources/images/cases_nonresponse.png" style="width: 45%; z-index: ;"/></td>  -->
  <!-- </tr> -->
  <!-- <tr>  -->
  <!--   <td><img src="./resources/images/model_c_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  <!--   <td><img src="./resources/images/model_d_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  <!-- </tr>  -->
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 1%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr> 
    <td><b>Noncompliance </b><span class="tiny">(Balke & Pearl '94)</td>
    <td><b>Outcome-based selection </b><span class="tiny">(Gabriel et al. '21)</td> 
  </tr> 
  <tr> 
    <td><img src="./resources/images/cases_iv.png" style="width: 45%; z-index: ;"/></td> 
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 45%; z-index: ;"/></td> 
  </tr>
  <tr> 
    <td><img src="./resources/images/model_a_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <td><img src="./resources/images/model_b_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
  </tr> 
  <tr style="height: 15px;"></tr>
  <tr>
    <td><b>Measurement error </b><span class="tiny">(Finkelstein et al. '20)</td> 
    <!-- <td><b>Nonresponse </b><span class="tiny">(Manski '90)</td>  -->
  </tr>
  <tr>
    <td><img src="./resources/images/cases_measurement.png" style="width: 45%; z-index: ;"/></td> 
    <!-- <td><img src="./resources/images/cases_nonresponse.png" style="width: 45%; z-index: ;"/></td>  -->
  </tr>
  <tr> 
    <td><img src="./resources/images/model_c_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <!-- <td><img src="./resources/images/model_d_trajectory_pres.png" style="width: 60%; z-index: ;"/></td>  -->
  </tr> 
</table>

---

<table class="center" style="position: absolute; left: 0%; top: 1%; width: 100%;">
  <colgroup>
    <col style="width: 50%;"/>
    <col style="width: 50%;"/>
  </colgroup>
  <tr> 
    <td><b>Noncompliance </b><span class="tiny">(Balke & Pearl '94)</td>
    <td><b>Outcome-based selection </b><span class="tiny">(Gabriel et al. '21)</td> 
  </tr> 
  <tr> 
    <td><img src="./resources/images/cases_iv.png" style="width: 45%; z-index: ;"/></td> 
    <td><img src="./resources/images/cases_outcomeselection.png" style="width: 45%; z-index: ;"/></td> 
  </tr>
  <tr> 
    <td><img src="./resources/images/model_a_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <td><img src="./resources/images/model_b_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
  </tr> 
  <tr style="height: 15px;"></tr>
  <tr>
    <td><b>Measurement error </b><span class="tiny">(Finkelstein et al. '20)</td> 
    <td><b>Nonresponse </b><span class="tiny">(Manski '90)</td> 
  </tr>
  <tr>
    <td><img src="./resources/images/cases_measurement.png" style="width: 45%; z-index: ;"/></td> 
    <td><img src="./resources/images/cases_nonresponse.png" style="width: 45%; z-index: ;"/></td> 
  </tr>
  <tr> 
    <td><img src="./resources/images/model_c_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
    <td><img src="./resources/images/model_d_trajectory_pres.png" style="width: 60%; z-index: ;"/></td> 
  </tr> 
</table>

???
For all of them, autobound came up with sharp bounds in matter of seconds.
It is important to emphasize again that some of these problems required 
authors many pages to solve them. And some are pretty recent.

I will omit it here, but autobound was able to solve other problems very quick, 
such as overlap, ecological inference, and problems of mixing observational and 
experimental information. Tomorrow I have a poster that shows how autobound 
 can be applied to calculate bounds for marginal effects in factorial experiments, 
 for instance.
Also, for point identification, autobound solved very quick cases such as 
the front-door criterion and the napkin problem, which are non-trivial.
---

class: center

<br><br><h2 style="color: black"><b>Dependent nonrandom missingness</b></h2>

<img src="./resources/images/cases_shadowvars.png" style="position: absolute; left: 12.5%; top: 35%; width: 75%; z-index: ;"/>

---

<img src="./resources/images/manski2_trajectory_pres_1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>

---

<img src="./resources/images/manski2_trajectory_pres_2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>

---

class: center

<br><br><h2 style="color: black"><b>Dependent nonrandom missingness</b></h2>

<img src="./resources/images/cases_shadowvars.png" style="position: absolute; left: 12.5%; top: 35%; width: 75%; z-index: ;"/>

<br><br><br><br><br><br><br><br>
Surprisingly, point identification with "shadow variables" demonstrated by Miao & Tchetgen Tchetgen ('16)

---
class: center, middle, inverse

# Testing all observable
# implications of assumptions

???
Here again we will use the IV example to show how autobound can help researchers 
to deal with classic queries.
---

<span style="position: absolute; left: 25%; top: 12.5%; width: 50%; z-index: ; text-align: center;"/>
<b>True data-generating process
</span>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 30%; top: 20%; width: 40%; z-index: ;"/>
???
We start by simulating a  data generating process of a simple instrumental variable. Everything is binary,
X and Y are confounded, and there is an not confounded IV Z causing X.
For the simulation, we have no restriction in terms of defiers. 
--
<span style="position: absolute; left: 0%; top: 52.5%; width: 50%; z-index: ; text-align: center;"/>
<b>Overly cautious assumptions
</span>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 5%; top: 60%; width: 40%; z-index: ;"/>
???
We choose to test different specifications, an overly cautious assumptions that assumes 
that Z might be also causing Y, not through X, which would violate the exclusion restriction 
assumption.
--
<span style="position: absolute; right: 0%; top: 52.5%; width: 50%; z-index: ; text-align: center;"/>
<b>Overly confident assumptions
</span>
<img src="./resources/images/iv_confident.png" style="position: absolute; right: 5%; top: 60%; width: 40%; z-index: ;"/>
???
 We also test the specification that there are no defiers. The  classic paper by 
Angrist, Imbens, and Rubin, suggest that when we add this assumption plus the assumption
that the probability of compliers is higher than the probability of always-takers 
and never-takers, then the ATE for the complier is point identified.
---

<img src="./resources/images/iv_legend.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv1.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
So here is what we have.
---

<img src="./resources/images/iv_legend.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv2.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
For the overly cautious assumptions case, 
both bounds were able to contain the true values of ATE and CATE, indicated by the 
dashed line. The sharp bounds for the ATE are sort of sharp, 
but the sharp bounds for the CATE are not informative, -1 and 1. This happens 
because exclusively counterfactual statements are very hard to estimate when 
specific assumptions fail.
---

<img src="./resources/images/iv_legend.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv3.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
This problem for the CATE exists even when we adopt the correct assumptions. So 
unless all the assumptions indicated by Angrist et al are valid, no CATE.
---

<img src="./resources/images/iv_legend.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv4.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
Finally, if we assume there are no defiers, something strange happens. It says that 
the model is unfeasible. Why does this happen?
This happens because the data is contradictory to the assumption 
that there are no defiers. 
Surprisingly, the estimator derived by Angrist, Imbens, and Rubin gets a super biased value, which I will show in two slides. 
---

<img src="./resources/images/iv_legend.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv5.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
In summary, for the models we can derive bounds, although in some cases, they are loose, especially
for some exclusively counterfactual quantities.
---

<img src="./resources/images/iv6.png" style="position: absolute; left: 2.5%; top: 2.5%; width: 95%; z-index: ;"/>
<img src="./resources/images/iv_cautious.png" style="position: absolute; left: 14%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_correct.png" style="position: absolute; left: 39.5%; top: 75%; width: 25%; z-index: ;"/>
<img src="./resources/images/iv_confident.png" style="position: absolute; left: 65%; top: 75%; width: 25%; z-index: ;"/>
???
However, A blindfold and incorrect 
application of Angrist estimator though would get a CATE of -0.75, which is very lower than the real CATE. It's this blue ball in the right.
---

class: center, middle, inverse

# Guaranteed conservative
# confidence intervals

???
- Now I'm going to very briefly describe a procedure for inference on these bounds

---
<img src="./resources/images/cases_xy.png" style="position: absolute; left: 2.5%; top: 30%; width: 95%; z-index: ;"/>
---
<img src="./resources/images/ci_point.png" style="position: absolute; left: -10%; top: 0%; height: 100%; z-index: ;"/>
---
<img src="./resources/images/ci_box.png" style="position: absolute; left: -10%; top: 0%; height: 100%; z-index: ;"/>
---

<img src="./resources/images/cases_iv.png" style="position: absolute; left: 2.5%; top: 30%; width: 95%; z-index: ;"/>
---
<img src="./resources/images/coverage.png" style="position: absolute; left: 2.5%; top: 10%; width: 95%; z-index: ;"/>

---

class: center, middle, inverse

# Ongoing work

---

# Ongoing work

1. General diagnostic toolkit for quantifying racial bias in any stage of
   policing with disparate datasets

--
2. Study of descriptive representation using public registry of officers,
   covering 97 of top 100 agencies

--
3. National inventory of civilian oversight orgs, best practices for police
   misconduct investigations

--
4. Collaborative project with police ethics training organization to evaluate
   efficacy, reform curriculum

--
5. Automated computer vision & speech processing to transform bodycam
   footage into accountability tool

---


class: center, middle, inverse

# Potential critiques
# of autobounding

---

# Potential critiques

- "The bounds may be too wide to be informative"

--
  - Yes.

--
This is a fact about the universe

--
  - Solution: collect more data or justify more assumptions
???
Also, someone might say that  sometimes the bounds are too wide to be informative. 
This happens, but they are the best bounds given extant information.
If researchers can justify more assumptions or gather more data, 
so they can have narrower bounds.

--

- "The user must know the true causal model"
  - Causal inference without assumptions is impossible
  - Our approach allows them to be relaxed modularly
???
Now I will address 
potential critiques on our method. The first one is 
that autobound requires that the researcher must know the true causal model. 
Well, indeed researchers have to assume a certain causal structure.
It is important to emphasize that causal inference is impossible without 
having causal structure assumptions. At least, independent and dependent 
variables must be specified. And I hypothesize that we can extend the method to capture 
more general structures, for example, PAGs rather than DAGs.

--

- "What about continuous variables?"
  - Discrete systems are a large part of applied work.
  - With more data, it is feasible to discretize variables.
???
Thirdly, one might complain that autobound only handle discrete 
variables. Well, discrete systems are a large part of applied work.
And, fortunately, researchers also can discretize variables, given a good 
amount of data. And overlap is not a concern for autobound. 

--

- "The bounds will take too long to compute"
  - Researchers can still narrow the range of answers
  - Our algorithm is "anytime," meaning bounds are always valid
  - More efficient methods are a key direction for future work
???
Finally, one must complain the bounds will take too long to compute.
This might happen sometimes, although in practice, the algorithm 
solves hard problems very quick. The point here is 
that researchers can stop autobound at any moment and get 
valid bounds even so.
Also, one of the main contributions of autobound is to generate a causal program.
New efficient algorithms can be employed to solve the same problems, and 
this is a developing research area.

---

class: center, middle, inverse

# "Computers are cheap
# and thinking hurts."
## &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;- Uwe's Maxim

<!-- THE END -->

    </textarea>

    <script src="js/remark-latest.min.js"></script>
    <!-- <script type="text/javascript" async -->
    <!--   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> -->
    <!--   // load MathJax -->
    <!--   MathJax.Hub.Config({ -->
    <!--       tex2jax: { -->
    <!--       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], -->
    <!--       inlineMath: [['$','$'], ['\\(','\\)']] -->
    <!--       }, -->
    <!--       "HTML-CSS": { -->
    <!--       availableFonts: "TeX", -->
    <!--       preferredFont: "Latin-Modern", -->
    <!--       webfont: "Latin-Modern" -->
    <!--       }, -->
    <!--   }); -->
    <!--   MathJax.Hub.Queue(function() { -->
    <!--       $(MathJax.Hub.getAllJax()).map(function(index, elem) { -->
    <!--           return(elem.SourceElement()); -->
    <!--       }).parent().addClass('has-jax'); -->
    <!--   }); -->
    <!--   MathJax.Hub.Configured(); -->
    <!-- </script> -->

    <script>
      // configure remark.js
      var slideshow = remark.create({
      countIncrementalSlides: false,
      navigation: {scroll: false},
      slideNumberFormat: ''
      });
    </script>

      <script>

        var videos = document.getElementsByClassName("media");
        function prepareCheckScroll(){
          window.setTimeout("checkScroll()", 1000);
        }
        function checkScroll() {

					for(var i = 0; i < videos.length; i++) {
						var video = videos[i];
						var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
						b = y + h, //bottom
						visibleX, visibleY, visible;
						visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
						visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));
						visible = visibleX * visibleY / (w * h);

						if (visible > .5) {
							video.play();
						} else {
							video.currentTime = 0;
							video.pause();
						}
					}
				}

				window.addEventListener('keydown', prepareCheckScroll, false);
				window.addEventListener('keyup', prepareCheckScroll, false);
      </script>

      <script>
        var months = new Array("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December");
        var today = new Date();
        var dateElements = document.getElementsByClassName('today');
        [].forEach.call(dateElements, function(dateElement){
        dateElement.innerHTML = today.getDate() + " " + months[today.getMonth()] + " " + today.getFullYear();
        })
      </script>

  </body>
</html>
